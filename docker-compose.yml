version: "3.7"
services:
  web:
    image: airflow
    build: .
    ports:
      - "8080:8080"
    depends_on:
      - db
      - redis
    environment:
      AIRFLOW__CORE__DAGS_FOLDER: "/airflow/dags"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__EXECUTOR: "CeleryExecutor"
      AIRFLOW__CELERY__BROKER_URL: "redis://redis:6379"
      AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://postgres@db/postgres"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://postgres@db/postgres"
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30
      AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT: "False"
      AIRFLOW_ENVIRONMENT: "stage"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_DEFAULT_REGION: "${AWS_DEFAULT_REGION}"
      ECS_CLUSTER: "${ECS_CLUSTER}"
      ECS_NETWORK_CONFIG: "${ECS_NETWORK_CONFIG}"
      ES_URL: "${ES_URL}"
    command: ["webserver"]
    volumes:
      - type: bind
        source: ./workflows
        target: /airflow/dags
  scheduler:
    image: airflow
    build: .
    depends_on:
      - db
      - redis
    environment:
      AIRFLOW__CORE__DAGS_FOLDER: "/airflow/dags"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://postgres@db/postgres"
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30
      AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT: "False"
      AIRFLOW__CORE__EXECUTOR: "CeleryExecutor"
      AIRFLOW__CELERY__BROKER_URL: "redis://redis:6379"
      AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://postgres@db/postgres"
      AIRFLOW_ENVIRONMENT: "stage"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_DEFAULT_REGION: "${AWS_DEFAULT_REGION}"
      ECS_CLUSTER: "${ECS_CLUSTER}"
      ECS_NETWORK_CONFIG: "${ECS_NETWORK_CONFIG}"
      ES_URL: "${ES_URL}"
    command: ["scheduler"]
    volumes:
      - type: bind
        source: ./workflows
        target: /airflow/dags
  worker:
    image: airflow
    build: .
    depends_on:
      - db
      - redis
    environment:
      AIRFLOW__CORE__DAGS_FOLDER: "/airflow/dags"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://postgres@db/postgres"
      AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 30
      AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT: "False"
      AIRFLOW__CORE__EXECUTOR: "CeleryExecutor"
      AIRFLOW__CELERY__BROKER_URL: "redis://redis:6379"
      AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://postgres@db/postgres"
      AIRFLOW_ENVIRONMENT: "stage"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_DEFAULT_REGION: "${AWS_DEFAULT_REGION}"
      ECS_CLUSTER: "${ECS_CLUSTER}"
      ECS_NETWORK_CONFIG: "${ECS_NETWORK_CONFIG}"
      ES_URL: "${ES_URL}"
    command: ["worker"]
    volumes:
      - type: bind
        source: ./workflows
        target: /airflow/dags
  db:
   image: postgres
   volumes:
     - type: volume
       source: db
       target: /var/lib/postgresql/data
  redis:
    image: redis
volumes:
  db:
